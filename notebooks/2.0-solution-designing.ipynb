{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Dasha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Dasha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Dasha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Dasha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "      <th>ref_tox</th>\n",
       "      <th>trn_tox</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>if alkar floods her with her mental waste it w...</td>\n",
       "      <td>if alkar is flooding her with psychic waste th...</td>\n",
       "      <td>0.981983</td>\n",
       "      <td>0.014195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i have orders to kill her</td>\n",
       "      <td>ive got orders to put her down</td>\n",
       "      <td>0.999348</td>\n",
       "      <td>0.009402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im not gonna have a child with the same geneti...</td>\n",
       "      <td>im not going to breed kids with a genetic diso...</td>\n",
       "      <td>0.950956</td>\n",
       "      <td>0.035846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>theyre all laughing at us so well kick your ass</td>\n",
       "      <td>theyre laughing at us well show you</td>\n",
       "      <td>0.999492</td>\n",
       "      <td>0.000131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>youd probably want me to buy you some chocolat...</td>\n",
       "      <td>i suppose you want me to buy you flowers and c...</td>\n",
       "      <td>0.980341</td>\n",
       "      <td>0.000078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           reference   \n",
       "0  if alkar floods her with her mental waste it w...  \\\n",
       "1                          i have orders to kill her   \n",
       "2  im not gonna have a child with the same geneti...   \n",
       "3    theyre all laughing at us so well kick your ass   \n",
       "4  youd probably want me to buy you some chocolat...   \n",
       "\n",
       "                                         translation   ref_tox   trn_tox  \n",
       "0  if alkar is flooding her with psychic waste th...  0.981983  0.014195  \n",
       "1                     ive got orders to put her down  0.999348  0.009402  \n",
       "2  im not going to breed kids with a genetic diso...  0.950956  0.035846  \n",
       "3                theyre laughing at us well show you  0.999492  0.000131  \n",
       "4  i suppose you want me to buy you flowers and c...  0.980341  0.000078  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_file = '../data/intermediate/filtered_data.tsv'\n",
    "\n",
    "data = pd.read_csv(data_file, sep='\\t')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize sentiment analyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Function to identify negative words based on sentiment analysis\n",
    "def identify_negative_words(text):\n",
    "    tokenized_text = word_tokenize(text)\n",
    "    pos_tags = nltk.pos_tag(tokenized_text)\n",
    "    \n",
    "    negative_words = []\n",
    "    for word, tag in pos_tags:\n",
    "        if sia.polarity_scores(word)['compound'] < 0:\n",
    "            # Check if word is an adverb (often intensify negativity)\n",
    "            if tag.startswith('RB') or tag.startswith('RBR') or tag.startswith('RBS'):\n",
    "                negative_words.append((word, tag, 'omit'))  # Mark for omission\n",
    "            else:\n",
    "                negative_words.append((word, tag, 'replace'))  # Mark for replacement\n",
    "    return negative_words\n",
    "\n",
    "# Function to find synonyms\n",
    "def get_synonyms(word):\n",
    "    synonyms = set()\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for lemma in syn.lemmas():\n",
    "            if lemma.name() != word:\n",
    "                synonyms.add(lemma.name().replace('_', ' '))\n",
    "    return list(synonyms)\n",
    "\n",
    "# Function to replace or omit negative words\n",
    "def modify_negative_words(text, negative_words):\n",
    "    tokenized_text = word_tokenize(text)\n",
    "    modified_text = []\n",
    "    \n",
    "    for word in tokenized_text:\n",
    "        negation = next((neg for neg in negative_words if neg[0] == word), None)\n",
    "        if negation:\n",
    "            word, tag, action = negation\n",
    "            if action == 'replace':\n",
    "                synonyms = get_synonyms(word)\n",
    "                if synonyms:\n",
    "                    word = synonyms[0]  # Just pick the first synonym for simplicity\n",
    "            elif action == 'omit':\n",
    "                word = ''  # Omit the word from the sentence\n",
    "        \n",
    "        # Add the word if it's not marked for omission\n",
    "        if word:\n",
    "            modified_text.append(word)\n",
    "            \n",
    "    return ' '.join(modified_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I hate this shit so much.</td>\n",
       "      <td>I hatred this Irish bull so much .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The food was fucking terrible.</td>\n",
       "      <td>The food was fucking fearful .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>He is a horrible nigger.</td>\n",
       "      <td>He is a horrifying spade .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>They are laughing because we will fuck up.</td>\n",
       "      <td>They are laughing because we will make out up .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    reference   \n",
       "0                   I hate this shit so much.  \\\n",
       "1              The food was fucking terrible.   \n",
       "2                    He is a horrible nigger.   \n",
       "3  They are laughing because we will fuck up.   \n",
       "\n",
       "                                       translation  \n",
       "0               I hatred this Irish bull so much .  \n",
       "1                   The food was fucking fearful .  \n",
       "2                       He is a horrifying spade .  \n",
       "3  They are laughing because we will make out up .  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame({\n",
    "    'reference': [\n",
    "        'I hate this shit so much.',\n",
    "        'The food was fucking terrible.',\n",
    "        'He is a horrible nigger.',\n",
    "        'They are laughing because we will fuck up.'\n",
    "    ]\n",
    "})\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    sentence = row['reference']\n",
    "    negative_words = identify_negative_words(sentence)\n",
    "    new_sentence = modify_negative_words(sentence, negative_words)\n",
    "    data.at[index, 'translation'] = new_sentence\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've added feature of ommiting negative sentiments words if there are no synonyms for them. But it didn't work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "def identify_negative_words(text):\n",
    "    tokenized_text = word_tokenize(text)\n",
    "    pos_tags = nltk.pos_tag(tokenized_text)\n",
    "    \n",
    "    negative_words = []\n",
    "    for word, tag in pos_tags:\n",
    "        if sia.polarity_scores(word)['compound'] < 0:\n",
    "            negative_words.append((word, tag))\n",
    "    return negative_words\n",
    "\n",
    "def get_synonyms(word):\n",
    "    synonyms = set()\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for lemma in syn.lemmas():\n",
    "            if lemma.name() != word:\n",
    "                synonyms.add(lemma.name().replace('_', ' '))\n",
    "    return list(synonyms)\n",
    "\n",
    "def modify_negative_words(text, negative_words):\n",
    "    for word, tag in negative_words:\n",
    "        synonyms = get_synonyms(word)\n",
    "        non_negative_synonyms = [syn for syn in synonyms if sia.polarity_scores(syn)['compound'] >= 0]\n",
    "        if non_negative_synonyms:\n",
    "            text = text.replace(word, non_negative_synonyms[0], 1)\n",
    "    return text\n",
    "\n",
    "def reframe_sentence(text, negative_words):\n",
    "    tokenized_text = word_tokenize(text)\n",
    "    for word, tag in negative_words:\n",
    "        # Check for negation patterns in the sentence\n",
    "        if word.lower() in [\"not\", \"no\", \"never\", \"n't\"] and len(tokenized_text) > tokenized_text.index(word) + 1:\n",
    "            # Attempt to negate the following word directly if it's an adjective or verb\n",
    "            next_word = tokenized_text[tokenized_text.index(word) + 1]\n",
    "            if tag.startswith('JJ') or tag.startswith('VB'):\n",
    "                synonyms = get_synonyms(next_word)\n",
    "                non_negative_synonyms = [syn for syn in synonyms if sia.polarity_scores(syn)['compound'] >= 0]\n",
    "                if non_negative_synonyms:\n",
    "                    # Replace the negation + word with a non-negative synonym\n",
    "                    text = text.replace(word + ' ' + next_word, non_negative_synonyms[0], 1)\n",
    "        else:\n",
    "            synonyms = get_synonyms(word)\n",
    "            non_negative_synonyms = [syn for syn in synonyms if sia.polarity_scores(syn)['compound'] >= 0]\n",
    "            if non_negative_synonyms:\n",
    "                text = text.replace(word, non_negative_synonyms[0], 1)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I hate this shit so much.</td>\n",
       "      <td>I detest this Irish bull so much.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The food was fucking terrible.</td>\n",
       "      <td>The food was fucking tremendous.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>He is a horrible nigger.</td>\n",
       "      <td>He is a atrocious spade.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>They are laughing because we will fuck up.</td>\n",
       "      <td>They are laughing because we will make out up.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    reference   \n",
       "0                   I hate this shit so much.  \\\n",
       "1              The food was fucking terrible.   \n",
       "2                    He is a horrible nigger.   \n",
       "3  They are laughing because we will fuck up.   \n",
       "\n",
       "                                      translation  \n",
       "0               I detest this Irish bull so much.  \n",
       "1                The food was fucking tremendous.  \n",
       "2                        He is a atrocious spade.  \n",
       "3  They are laughing because we will make out up.  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame({\n",
    "    'reference': [\n",
    "        'I hate this shit so much.',\n",
    "        'The food was fucking terrible.',\n",
    "        'He is a horrible nigger.',\n",
    "        'They are laughing because we will fuck up.'\n",
    "    ]\n",
    "})\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    sentence = row['reference']\n",
    "    negative_words = identify_negative_words(sentence)\n",
    "    \n",
    "    # Step 1: Modify negative words\n",
    "    modified_sentence = modify_negative_words(sentence, negative_words)\n",
    "    \n",
    "    # Step 2: Check the sentiment of the modified sentence\n",
    "    reframed_sentence = reframe_sentence(modified_sentence, negative_words)\n",
    "    data.at[index, 'translation'] = reframed_sentence\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've added sentence reconstruction after pulling in synonyms. It didn't work well.\n",
    "\n",
    "Let's try different approach.\n",
    "\n",
    "I downloaded list of banned words from https://www.freewebheaders.com/full-list-of-bad-words-banned-by-google/ by Google. Let's try to work with this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>banned_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2 girls 1 cup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2g1c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4r5e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5h1t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5hit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     banned_word\n",
       "0  2 girls 1 cup\n",
       "1           2g1c\n",
       "2           4r5e\n",
       "3           5h1t\n",
       "4           5hit"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "banned_words_file = '../data/external/bad-words.txt'\n",
    "\n",
    "with open(banned_words_file, 'r') as file:\n",
    "    banned_words_list = file.read().splitlines()\n",
    "\n",
    "# Convert the list into a DataFrame\n",
    "banned_df = pd.DataFrame(banned_words_list, columns=['banned_word'])\n",
    "\n",
    "banned_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_synonyms(word):\n",
    "    synonyms = set()\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for lemma in syn.lemmas():\n",
    "            if lemma.name().lower() != word:\n",
    "                synonyms.add(lemma.name().lower().replace('_', ' '))\n",
    "    return list(synonyms)\n",
    "\n",
    "# Define the function to identify and replace negative phrases\n",
    "def detoxify_sentence(sentence, banned_words_df):\n",
    "    # Lowercase the sentence to ensure proper matching\n",
    "    lowered_sentence = sentence.lower()\n",
    "    for banned_phrase in banned_words_df['banned_word']:\n",
    "        # Check if the banned phrase is in the sentence\n",
    "        if re.search(r'\\b' + re.escape(banned_phrase) + r'\\b', lowered_sentence, flags=re.IGNORECASE):\n",
    "            # Split the banned phrase to check for synonyms for single words only\n",
    "            banned_words = banned_phrase.split()\n",
    "            # Only find synonyms if the banned phrase is a single word\n",
    "            if len(banned_words) == 1:\n",
    "                synonyms = get_synonyms(banned_words[0])\n",
    "                if synonyms:\n",
    "                    replacement = synonyms[0]\n",
    "                else:\n",
    "                    replacement = ''\n",
    "            else:\n",
    "                # For multi-word phrases, it's more complex to find synonyms\n",
    "                # So we'll opt to just remove the phrase\n",
    "                replacement = ''\n",
    "            # Replace the banned phrase with the replacement or remove it\n",
    "            sentence = re.sub(r'\\b' + re.escape(banned_phrase) + r'\\b', replacement, sentence, flags=re.IGNORECASE)\n",
    "    return sentence.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>That was a stupid idea, you ass dlck!</td>\n",
       "      <td>That was a pudden-head idea, you nates !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Motherfucka! a55! style doggy!</td>\n",
       "      <td>! ! !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>He is such a jerk when he drinks.</td>\n",
       "      <td>He is such a twitch when he drinks.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>She is a slutty fox in her debates.</td>\n",
       "      <td>She is a slutty fox in her debates.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>They are laughing because we will fuck up.</td>\n",
       "      <td>They are laughing because we will make out up.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    reference   \n",
       "0       That was a stupid idea, you ass dlck!  \\\n",
       "1              Motherfucka! a55! style doggy!   \n",
       "2           He is such a jerk when he drinks.   \n",
       "3         She is a slutty fox in her debates.   \n",
       "4  They are laughing because we will fuck up.   \n",
       "\n",
       "                                      translation  \n",
       "0        That was a pudden-head idea, you nates !  \n",
       "1                                           ! ! !  \n",
       "2             He is such a twitch when he drinks.  \n",
       "3             She is a slutty fox in her debates.  \n",
       "4  They are laughing because we will make out up.  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame({\n",
    "    'reference': [\n",
    "        'That was a stupid idea, you ass dlck!',\n",
    "        'Motherfucka! a55! style doggy!',\n",
    "        'He is such a jerk when he drinks.',\n",
    "        'She is a slutty fox in her debates.',\n",
    "        'They are laughing because we will fuck up.',\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Apply the detoxify_sentence function to the 'reference' column\n",
    "data['translation'] = data['reference'].apply(lambda x: detoxify_sentence(x, banned_df))\n",
    "\n",
    "data.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
